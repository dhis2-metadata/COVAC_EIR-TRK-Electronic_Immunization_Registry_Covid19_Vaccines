name: Publish

on:
  push:
    tags:
      - '**'

  # Enable button for manual trigger
  workflow_dispatch:

# Environment variables used as input
env:
  CODE: 'COVAC'
  # Name or Type (aggregate, tracker, event, add_on)?
  NAME: 'Registry'
  TYPE: 'tracker'

jobs:
  prepare:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - id: set-matrix
        run: |
          # create array/json object of source files to destination filenames
          echo "::set-output name=matrix::$(bash .github/scripts/prepare-matrix.sh)"
      outputs:
        matrix: ${{ steps.set-matrix.outputs.matrix }}

  publish:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        files: ${{fromJson(needs.prepare.outputs.matrix)}}
    steps:
      - uses: actions/checkout@v2

      - name: 'Upload package'
        uses: dhis2/s3-sync-action@test
        with:
          # TODO: set ACL "--acl public-read" when public
          # Symlinks? --follow-symlinks
          # Delete?
          args: --delete
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BOT_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BOT_SECRET_KEY }}
          AWS_S3_BUCKET: ${{ secrets.S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          SOURCE_DIR: ${{ matrix.files.source }}
          DEST_DIR: ${{ matrix.files.destination }}

      # OLD
      #- name: 'Set destination'
      # Construct destination for upload:
      # 1. Remove unneeded part of ref
      # 2. Split the remaining into array by "/"
      # 3. Get DHIS2 and Metadata versions from array
      #        run: |
      #          SHORT_REF="${GITHUB_REF#refs/tags/}"
      #          SPLIT_REF=(${SHORT_REF//\// })
      #          DHIS="${SPLIT_REF[0]#D}"
      #          META="${SPLIT_REF[1]}"
      #          echo "DESTINATION=$CODE/$TYPE/$META/$DHIS" >> $GITHUB_ENV
      #      - name: 'Check if dashboard is available'
      #        id: check_dashboard
      #        uses: andstor/file-existence-action@v1
      #        with:
      #          files: 'dashboard'
      #      - name: 'Upload "dashboard" package'
      #        if: steps.check_dashboard.outputs.files_exists == 'true'
      #        uses: dhis2/s3-sync-action@test
      #        with:
      #          args: --delete
      #        env:
      #          AWS_ACCESS_KEY_ID: ${{ secrets.BOT_ACCESS_KEY }}
      #          AWS_SECRET_ACCESS_KEY: ${{ secrets.BOT_SECRET_KEY }}
      #          AWS_S3_BUCKET: ${{ secrets.S3_BUCKET }}
      #          AWS_REGION: 'eu-west-1'
      #          SOURCE_DIR: 'dashboard'
      #          DEST_DIR: "$DESTINATION/dashboard"
